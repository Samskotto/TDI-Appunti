{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da53909d-17c5-4915-b533-e693eb61fce2",
   "metadata": {},
   "source": [
    "Analizziamo ora la relazione che ha l'**entropia** $H(X)$ con il **valore atteso delle lunghezze** $E[l_c]$(o lunghezza media delle parole di un codice istantaneo). Per capire questa relazione introduciamo una misura **non intercambiabile** ( ciò significa che se calcolo questa misura tra $A$ e $B$ è diversa che se la calcolo tra $B$ e $A$) che <mark>calcola la diversità tra due variabili aleatorie $X$ e $Y$ definite sullo stesso dominio $\\mathbb{S}$</mark>.\n",
    "## Entropia relativa\n",
    "Definiamo l'entropia relativa in base $D > 1$ tra due variabili aleatorie $X$ e $Y$ come:\n",
    "$$\n",
    "    D(X || Y) = \\sum_{s \\in \\mathbb{S}} p_x(s) \\cdot \\log_D \\frac{p_x(s)}{p_y(s)}\n",
    "$$\n",
    "Con $D(X || Y) \\neq D(Y || X)$.\n",
    "*Semanticamente* è la misura dell'informazione persa quando $Y$ è usata per approssimare $X$ (Il dominio nel nostro caso sarà la nostra sorgente)\n",
    "Cosa succede se $p_X(s) = 0$ e $p_Y(s) = 0$?\n",
    "\n",
    "Notiamo che la sommatoria \n",
    "\\begin{align}\n",
    "\\sum_{s \\in \\mathbb{S}} 0 \\cdot \\log_D \\frac{0}{0} \\quad (1)\\\\\n",
    "\\end{align}\n",
    "Per **convenzione** sappiamo che $0 \\cdot \\log_D \\frac{0}{0} = 0$. Se invece solo $p_Y(s)= 0$\n",
    "\\begin{align}\n",
    "&\\sum_{s \\in \\mathbb{S}}  p_X(s) \\cdot \\log_D \\frac{p_X(s)}{0} \\quad (2)\\\\\n",
    "&\\sum_{s \\in \\mathbb{S}}  p_X(s) \\cdot \\log_D \\frac{p_X(s)}{0} \\rightarrow \\infty \\quad (3)\n",
    "\\end{align}\n",
    "Sempre per convenzione questo valore tende ad infinito. Se invece calcoliamo l'entropia relativa come $D(X || X)$ allora\n",
    "\\begin{align}\n",
    " D(X || X) &= \\sum_{s \\in \\mathbb{S}}  p_X(s) \\cdot \\log_D \\frac{p_X(s)}{p_X(s)} \\quad (1)\\\\\n",
    "&= \\sum_{s \\in \\mathbb{S}}  p_X(s) \\cdot \\log_D 1 \\quad (2)\\\\\n",
    "D(X || X) &= 0 \\quad (3)\\\\\n",
    "\\end{align} \n",
    "### Teorema\n",
    "Per ogni coppia $X,Y$ di variabili aleatorie definite sul dominio $\\mathbb{S}$ vale $D(X||Y) \\geq 0$\n",
    "### <mark>Dimostrazione<mark>\n",
    "Dalla definizione di **entropia relativa** cambiamo la base del logaritmo, passando al logaritmo naturale\n",
    "\\begin{align}\n",
    " D(X || Y) &= \\sum_{s \\in \\mathbb{S}}  p_X(s) \\cdot \\log_D \\frac{p_X(s)}{p_Y(s)} \\quad \\quad &(1)\\\\\n",
    "&= \\sum_{s \\in \\mathbb{S}}  p_X(s) \\cdot \\ln \\frac{p_X(s)}{p_Y(s)} \\cdot \\frac{1}{\\ln D} \\quad \\quad &(2)\\\\\n",
    "\\end{align}\n",
    "Introduciamo il minorante del logaritmo naturale che è $1- \\frac{1}{x}$ e riscrviamo\n",
    "\\begin{align}\n",
    "&= \\frac{1}{\\ln D} \\cdot \\sum_{s \\in \\mathbb{S}}  p_X(s) \\cdot \\ln \\frac{p_X(s)}{p_Y(s)} \\geq \\frac{1}{\\ln D} \\cdot \\sum_{s \\in \\mathbb{S}}  p_X(s) \\cdot \\left(1 - \\frac{p_Y(s)}{p_X(s)}\\right)  \\quad \\quad &(3)\\\\\n",
    "\\end{align}\n",
    "Guardando la parte destra della disequazione distribuisco $p_X$\n",
    "\\begin{align}\n",
    "&=\\frac{1}{\\ln D} \\cdot \\sum_{s \\in \\mathbb{S}}  p_X(s) - p_Y(s) \\quad \\quad &(4)\\\\\n",
    "&=\\frac{1}{\\ln D} \\cdot \\left[\\sum_{s \\in \\mathbb{S}}  p_X(s) - \\sum_{s \\in \\mathbb{S}} p_Y(s) \\right]\\quad \\quad &(5)\\\\\n",
    "&=\\frac{1}{\\ln D} \\cdot \\left[1 - 1\\right]\\quad \\quad &(6)\\\\\n",
    "&= 0\\quad \\quad &(7)\\\\\n",
    "\\end{align}\n",
    "Quindi ricomponendo la disequazione abbiamo dimostrato che $D(X || Y) \\geq 0$.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0013fb7-83e4-41ba-9146-cc427c51d9e9",
   "metadata": {},
   "source": [
    "## Esercizio\n",
    "\n",
    "<img src=\"Media/Esercizio-03.png\" style=\"width:400px\">\n",
    "\n",
    "1. Per calcolare $H(X),H(Y)$ utilizzo la tabella delle probabilità congiunte per ricavarmi le probabilità marginali $p_X(0) = \\frac{2}{3}, p_X(1) = \\frac{1}{3}$ e $p_Y(0) = \\frac{1}{3}, p_Y(1) = \\frac{2}{3}$\n",
    "   $$\n",
    "       \\begin{align}\n",
    "           H(X) &= H(Y) = \\frac{2}{3}\\cdot \\log_2\\frac{3}{2} + \\frac{1}{3}\\cdot\\log_2 3 = 0.91\n",
    "       \\end{align}\n",
    "   $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0cd0e-e094-47be-bccf-6ffc6667ce50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

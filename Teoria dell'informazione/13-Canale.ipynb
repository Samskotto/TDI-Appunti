{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "222a900b-7e02-4f7e-98be-b41c33779fd7",
   "metadata": {},
   "source": [
    "Durante la **compressione rimuoviamo tutta la ridondanza nei dati** per ottenere la versione più compressa possibile, mentre durante la **trasmissione dei dati aggiungiamo ridondanza** in modo controllato per contrastare gli errori del canale.\n",
    "\n",
    "Per ora ci siamo concentrati quindi sulla prima parte del problema che aveva formulato Shannon, ovvero\n",
    "cercare di comprimere al massimo il messaggio da spedire sul canale. Ora ci concentriamo sul secondo\n",
    "problema, ovvero **cercare di codificare il canale stesso per aggiungere ridondanza**.\n",
    "\n",
    "Definiamo il **canale discreto senza memoria** la tupla $<\\mathbb{X},\\mathbb{Y}, p(Y|X)>$ composta da:\n",
    "1. L'insieme dei simboli della sorgente $\\mathbb{X}$\n",
    "2. L'insieme dei simboli del ricevente $\\mathbb{Y}$\n",
    "3. $p(Y|X)$ cioè la probabilità di ottenere $y \\in Y$ sapendo che è stato ricevuto $x \\in X$. Questa probabilità è la matrice di canale, che ci consente di definire il comportamento del canale.\n",
    "\n",
    "Il fatto di aggiungere la proprietà **senza memoria** indica che <mark>il canale si disinteressa di quello che è stato spedito prima del carattere appena ricevuto e di quello che verrà spedito dopo il carattere appena ricevuto</mark>. Questo significa che se spediamo $x^n$(un messaggio di $n$ simboli) il calcolo della probabilità si semplifica in:\n",
    "$$\n",
    "\\begin{align}\n",
    "    p(y^n|x^n) = \\prod_{j = 1}^{n} p(y_j | x_j)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Un'altra proprietà da definire sul canale è la sua **capacità** $C$ che è definita come la massima informazione mutua tra $X$ e $Y$ al variare di tutte le distribuzioni di probabilità $p(x)$ che può assumere:\n",
    "$$\n",
    "\\begin{align}\n",
    "    C = \\max_{p(x)} I(X;Y)\n",
    "\\end{align}\n",
    "$$\n",
    "*Sostanzialmente*: **la capacità di canale rappresenta la massima informazione che possiamo trasmettere** quando accediamo al canale.\n",
    "\n",
    "Ma qual'è **l'upper e il lower bound** della **capacità di canale**? Noi sappiamo che $I(X;Y) \\geq 0$ e inoltre possiamo riscrivere l'informazione mutua come\n",
    "1. $I(X;Y) = H(X) - H(X|Y)$\n",
    "2. $I(X;Y) = H(Y) - H(Y|X)$\n",
    "Sapendo che l'**entropia** ha sempre come **upper bound** $\\log |X|$ possiamo scrivere l'**upper bound** dell'informazione mutua come\n",
    "$$\n",
    "    H(X) - H(X|Y) \\leq \\log |X| \\quad \\text{oppure} \\quad H(Y) - H(Y|X) \\leq \\log |Y|\n",
    "$$\n",
    "Tra queste due forme dobbiamo scegliere **l'upper bound minore** quindi **la capacità di canale**\n",
    "$$\n",
    "    0\\leq C \\leq \\min (\\log|X|, \\log|Y|) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91a311e-ac3a-4d37-987e-3becc9291995",
   "metadata": {},
   "source": [
    "### Canale Binario senza rumore\n",
    "<img src=\"Media/Noisless-Binary-Channel.png\" alt=\"drawing\" style=\"align: center; width:300px;\"/>\n",
    "\n",
    "E'un canale binario dove **ciò che viene inviato in input è riprodotto esattamente in output**. In questo caso ogni bit trasmesso viene ricevuto senza errori, quindi per ogni utilizzo del canale viene trasmesso $1$ bit. Costruiamo **la matrice di canale**:\n",
    "$$\n",
    "p_{(Y\\mid X)} =\n",
    "\\begin{array}{c|cc}\n",
    "    & y_1 = 0 & y_2 = 1 \\\\ \\hline\n",
    "x_1 = 0 & p(y_1\\mid x_1) = 1 & p(y_2\\mid x_1) = 0 \\\\\n",
    "x_2 = 1 & p(y_1\\mid x_2) = 0 & p(y_2\\mid x_2) = 1 \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "Se studiamo $I(X;Y) = H(X) - H(X|Y)$ sappiamo che $H(X|Y) = 0$ perchè dal momento che ricevo un simbolo $y \\in Y$ so già che $X$ ha trasmesso $x$ quindi la conoscenza di $Y$ non ci da informazioni sulla conoscenza di $X$. Quindi **la capacità di canale diventa**\n",
    "$$\n",
    "\\begin{align}\n",
    "    C = \\max_{p(x)} H(X) \\leq \\log_2 2\n",
    "\\end{align}\n",
    "$$\n",
    "Ma qual è la probabilità $p(x)$ che rende massima $H(X)$? Ricordando che l'entropia massima si verifica quando **ho eventi equiprobabili** se $p(x) = \\frac{1}{2}$ (ho pari probabilità di trasmettere il simbolo $0$ o il simbolo $1$, *Bernoulliana*) allora $H(X) = 1$, quindi la capacità del canale è pari a $1$-bit di informazione ad ogni suo utilizzo.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70302f5f-7108-4752-a932-0336982ec743",
   "metadata": {},
   "source": [
    "### Canale con rumore e uscite disgiunte\n",
    "<img src=\"Media/Canale-Rumoroso-Uscite-Disgiunte.png\" alt=\"drawing\" style=\"align: center; width:300px;\"/>\n",
    "\n",
    "Costruiamo la **matrice di canale**:\n",
    "$$\n",
    "p_{(Y\\mid X)} =\n",
    "\\begin{array}{c|cc}\n",
    "    & y_1 = 1 & y_2 = 2 & y_3 = 3 & y_4 = 4 \\\\ \\hline\n",
    "x_1 = 0  & 0.5 &0.5 &0 &0  \\\\\n",
    "x_2 = 1 &0 &0 &0.3 &0.7\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "Il canale non è affetto da rumore perchè dato $Y$ sappiamo già qual'è il valore assunto da $X$ di conseguenza anche in questo caso **la capacità di canale** è pari a $1$-bit.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd77444e-bd9f-4205-8af4-cb8acda343ed",
   "metadata": {},
   "source": [
    "### Macchina da scrivere rumorosa\n",
    "Costruiamo la matrice di canale come: \n",
    "$$\n",
    "p_{(Y\\mid X)} =\n",
    "\\begin{array}{c|ccc}\n",
    "    & y_0 = 0 & y_1 = 1 & y_2 = 2 \\\\ \\hline\n",
    "x_0 = 0 &\\frac{1}{2}  &\\frac{1}{2} &0  \\\\\n",
    "x_1 = 1 &0 &\\frac{1}{2} &\\frac{1}{2}\\\\\n",
    "x_2 = 1 &\\frac{1}{2} &0 &\\frac{1}{2}\n",
    "\\end{array}\n",
    "$$\n",
    "Calcoliamo ora la capacità di canale $C$: \n",
    "$$\n",
    "\\begin{align}\n",
    "    I(X;Y) = H(X) - H(Y\\mid X) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "$$\n",
    "    H(Y\\mid X) = p(X = 0) \\cdot H(Y\\mid X = 0) + p(X = 1) \\cdot H(Y\\mid X = 1) + p(X = 2) \\cdot H(Y\\mid X = 2) \n",
    "$$\n",
    "Quindi se calcolo:\n",
    "$$\n",
    "\\begin{align}\n",
    "    H(Y \\mid X = 0) &= 2\\cdot(0.5\\cdot\\log\\frac{1}{0.5}) = 1\\\\\n",
    "    H(Y \\mid X = 1) &= 1\\\\\n",
    "    H(Y \\mid X = 2) &= 1\n",
    "\\end{align}\n",
    "$$\n",
    "Dato che dobbiamo trovare una distribuzione $p(x)$ che massimizza l'entropia $H(Y)$, sapendo che l'entropia è massima quando gli eventi sono equiprobabili assegno la distribuzione uniforme $p(x) = \\frac{1}{3}$ e calcolo \n",
    "$$\n",
    "    C = \\max_{p(x)}(H(Y) - 1) = \\sum_{i=0}^{2} p(Y = i)\\cdot \\log \\frac{1}{p(Y = i)} = 3\\cdot\\Big(\\frac{1}{3} \\log\\frac{1}{\\frac{1}{3}}\\Big) = \\log 3 - 1\n",
    "$$\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0c586a-576a-494b-b5c4-2098acf0e966",
   "metadata": {},
   "source": [
    "### Canale Binario Simmetrico\n",
    "<img src=\"Media/Canale-Binario-Simmetrico.png\" alt=\"drawing\" style=\"align: center; width:300px;\"/>\n",
    "\n",
    "In questo tipo di canale consideriamo $p$ come la probabilità di commettere un'errore, la matrice di canale risulta essere:\n",
    "$$\n",
    "p_{(Y\\mid X)} =\n",
    "\\begin{array}{c|ccccc}\n",
    "    & y_1 = 0 & y_2 = 1\\\\ \\hline\n",
    "x_1 = 0  &1-p &p   \\\\\n",
    "x_2 = 1 &p &1-p\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "Calcoliamo la capacità di canale: \n",
    "$$\n",
    "\\begin{align}\n",
    " I(X;Y) &= H(Y) - H(Y|X)  \\quad &(1)\\\\\n",
    " H(Y|X) &= \\sum_{i=0}^{1} p(X = i) \\cdot H(Y|X = i)   \\quad &(2)\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "Se calcoliamo $H(Y| X = i)$ per $i \\in \\{0,1\\}$ otteniamo:\n",
    "$$\n",
    "\\begin{align}\n",
    "    H(Y|X = 0) &= p(Y = 0 | X = 0) \\cdot \\log_2 \\frac{1}{p(Y = 0 | X = 0)} + p(Y = 1 | X = 0) \\cdot \\log_2 \\frac{1}{p(Y = 1 | X = 0)} \\quad &(1)\\\\\n",
    "    \\\\\n",
    "    & = (1-p) \\cdot \\log_2 \\frac{1}{(1-p)} + p\\cdot \\log_2 \\frac{1}{p} = H(p) \\quad &(2) \\\\\n",
    "    \\\\\n",
    "    H(Y| X = 1) = H(p)\n",
    "\\end{align}\n",
    "$$\n",
    "Dal punto $(2)$ notiamo che questa entropia che abbiamo scritto è pari **all'entropia di una variabile Bernoulliana**. Di conseguenza se ritorniamo a calcolare $H(Y|X) = \\sum_{i=0}^{1} p(X = i) \\cdot H(Y|X = i)$:\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\sum_{i=0}^{1} p(X = i) \\cdot H(p)\\\\\n",
    "&\\Big[p(X = 0)+p(X = 1)\\Big]\\cdot H(p) = H(p)\n",
    "\\end{align}\n",
    "$$\n",
    "Quindi $C = \\max_{p(x)}\\Big(H(Y) - H(p)\\Big)$ quindi $H(Y)$ è uguale a:\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\sum_{i=0}^{1} p(Y = i)\\cdot\\log_2 \\frac{1}{p(Y = i)} \\quad &(1)\\\\\n",
    "&p(Y = 0)\\cdot\\log_2 \\frac{1}{p(Y = 0)} + p(Y = 1)\\cdot\\log_2 \\frac{1}{p(Y = 1)}\\quad &(2)\\\\\n",
    "\\\\\n",
    "p(Y = 0) &= p(Y = 0| X = 0) p(X = 0) + p(Y = 0| X = 1) p(X = 1) \\\\\n",
    "&= \\Big[1-p \\cdot \\frac{1}{2}\\Big] + \\Big[p \\cdot \\frac{1}{2}\\Big] = \\frac{1}{2}\\\\\n",
    "\\\\\n",
    "p(Y = 1) &= \\frac{1}{2}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "Quindi $C = 1 - H(p)$\n",
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76182c8a-7506-407c-8354-7d5b69f1c113",
   "metadata": {},
   "source": [
    "### Canale Binario a Cancellazione\n",
    "\n",
    "<img src=\"Media/Binary-Erasure-Channel.png\" alt=\"drawing\" style=\"align: center; width:300px;\"/>\n",
    "\n",
    "Calcoliamo la capacità di canale introducendo una variabile *Bernoulliana*$Z$ di parametro $\\alpha$:\n",
    "$$\n",
    "Z = \\begin{cases}\n",
    "    &\\alpha \\quad &\\text{se} \\quad Y = e\\\\\n",
    "    &1-\\alpha \\quad &\\text{altrimenti}\n",
    "\\end{cases}\n",
    "$$\n",
    "Dato che vogliamo calcolare l'informazione mutua per trovare la capacità di canale $I(X;Y) = H(Y) - H(Y|X)$ per la **Chain rule**,ma $H(Y|X)$ è modellata da $Z$ quindi $H(Y|X) = H(Z)$. Per calcolare invece $H(Y)$ sappiamo sempre per la **Chain rule** che:\n",
    "$$\n",
    "    H(Y,Z) = H(Y) + H(Z | Y) = H(Z) + H(Y|Z)\n",
    "$$\n",
    "Ma quindi se consideriamo $H(Z | Y) = 0$ perchè se riceviamo $Y$ conosciamo già quanto varrà $Z$.\n",
    "$$\n",
    "    H(Y) = H(Z) + H(Y|Z) \n",
    "$$\n",
    "Dobbiamo quindi calcolare $H(Y|Z)$\n",
    "$$\n",
    "\\begin{align}\n",
    " H(Y|Z) &= p(Z = 0) \\cdot H(Y|Z=0) + p(Z = 1)\\cdot H(Y|Z = 1) \\\\\n",
    " &= 1-\\alpha \\cdot H(Y|Z = 0) + p(Z = 1) \\cdot H(Y|Z = 1)\n",
    "\\end{align}\n",
    "$$\n",
    "- $H(Y|Z = 1) = 0$\n",
    "- $H(Y|Z = 0)$ questa entropia è pari a $H(X)$ perchè se $Z = 0$ vuol dire che $Y$ ha ricevuto correttamente o $0,1$ quindi dipende solo da $X$.\n",
    "Di conseguenza $H(Y|Z) = 1 - \\alpha \\cdot H(X)$, quindi $H(Y) = H(Z) + H(X)\\cdot(1-\\alpha)$ e se sostituiamo dentro all'informazione mutua:\n",
    "$$\n",
    "    I(X;Y) = H(Z) + H(X)\\cdot(1-\\alpha) - H(Z) = H(X) \\cdot (1 - \\alpha)\n",
    "$$\n",
    "Ma dato che vogliamo trovare la distribuzione massima per calcolare la capacità di canale\n",
    "$$\n",
    "    C = \\max_{p(x)} I(X;Y) = (1 - \\alpha)\\cdot \\max_{p(x)} H(X)\n",
    "$$\n",
    "Dato che $X = \\{0,1\\}$ è *Bernoulliana* $H(X)$ è massima quando $p(x) = \\frac{1}{2}$ di conseguenza $H(X) = 1$, e quindi **la capacità di canale** è pari a\n",
    "$$\n",
    "    C = 1 - \\alpha\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319ef800-230b-4520-878c-e30be60bc9ee",
   "metadata": {},
   "source": [
    "Ciao come stai? \n",
    "\n",
    "$HOOOOOOOOO$\n",
    "\n",
    "$GUARDA LO SCHERMOOOOOOOOO$ DIOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fa658b-fb88-4a27-ae5e-94bbfddc8e67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
